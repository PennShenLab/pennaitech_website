{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "1. Blei DM, Ng AY, et al. Latent dirichlet allocation. Journal of machine Learning research. 2003;3(Jan):993-1022.\n",
        "2. Pham CM, et al. Topicgpt: A prompt-based topic modeling framework. Proc of NAACL. 2024.\n",
        "3. Rijcken E, et al. Towards interpreting topic models with ChatGPT. In: Proc of IFSA; 2023."
      ],
      "metadata": {
        "id": "Deu9DDG5Z-Ij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "warm up: directly prompt LLM UI"
      ],
      "metadata": {
        "id": "OvCBJqTdXris"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# warm up: directly prompt LLM UI (with Deep Research)\n",
        "prompt0 = \"\"\"You are the best expert in academic paper topic detection. The attached file contains 100 abstract texts for pubmed papers, read the abstract from each entry, summariez 6 most common topics for them. You will analyze step by step to cover all 100 abstract\"\"\"\n",
        "\n",
        "print(prompt0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFJLwVC_XAxc",
        "outputId": "376b6ede-a3ff-4fb9-a5c3-014fc9cabf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are the best expert in academic paper topic detection. The attached file contains 100 abstract texts for pubmed papers, read the abstract from each entry, summariez 6 most common topics for them. You will analyze step by step to cover all 100 abstract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-assisted Topic modeling with LDA"
      ],
      "metadata": {
        "id": "4m3IHkgpXu6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2FPAlG7DbTi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data files for preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'\\W', ' ', text)\n",
        "        text = re.sub(r'\\d', ' ', text)\n",
        "        text = text.lower()  # Convert to lower case\n",
        "        text = text.split()  # Split into individual words\n",
        "        text = [self.lemmatizer.lemmatize(word) for word in text if word not in self.stop_words]  # Lemmatize and remove stop words\n",
        "        return ' '.join(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfZnM_qIDezb",
        "outputId": "c555ac3c-d0d0-4f84-9acb-05f82aa0a856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KhkMP2tNDv3g",
        "outputId": "94e3bea6-ee37-4641-bdc0-63f854c69ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'ad+aging-v3_2011_100.jsonl'\n",
        "df = pd.read_json(data, lines=True)"
      ],
      "metadata": {
        "id": "SPVmXT8JE6pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the abstracts\n",
        "preprocessor = DataPreprocessor()\n",
        "df['processed_text'] = df['text'].apply(preprocessor.preprocess)\n"
      ],
      "metadata": {
        "id": "Rpd6PyUjMENS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8h-f0ldUMZlM",
        "outputId": "b1a33e5b-595e-42e0-a6c4-28ff467ff847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                               text  \\\n",
              "0      0  Convolutional neural networks for classificati...   \n",
              "1      1  MUTATE: a human genetic atlas of multiorgan ar...   \n",
              "2      2  MUTATE: a human genetic atlas of multiorgan ar...   \n",
              "3      3  Disentangling Normal Aging From Severity of Di...   \n",
              "4      4  CellTICS: an explainable neural network for ce...   \n",
              "..   ...                                                ...   \n",
              "140  140  STAB2: an updated spatio-temporal cell atlas o...   \n",
              "141  141  CirGRDB: a database for the genome-wide deciph...   \n",
              "142  142  MethBank 4.0: an updated database of DNA methy...   \n",
              "143  143  A metabolome atlas of the aging mouse brain. T...   \n",
              "144  144  MassCube improves accuracy for metabolomics da...   \n",
              "\n",
              "                                        processed_text  \n",
              "0    convolutional neural network classification al...  \n",
              "1    mutate human genetic atlas multiorgan artifici...  \n",
              "2    mutate human genetic atlas multiorgan artifici...  \n",
              "3    disentangling normal aging severity disease vi...  \n",
              "4    celltics explainable neural network cell type ...  \n",
              "..                                                 ...  \n",
              "140  stab updated spatio temporal cell atlas human ...  \n",
              "141  cirgrdb database genome wide deciphering circa...  \n",
              "142  methbank updated database dna methylation acro...  \n",
              "143  metabolome atlas aging mouse brain mammalian b...  \n",
              "144  masscube improves accuracy metabolomics data p...  \n",
              "\n",
              "[145 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-159efc7a-05e6-449f-9fa8-25c16c7cd60e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Convolutional neural networks for classificati...</td>\n",
              "      <td>convolutional neural network classification al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>MUTATE: a human genetic atlas of multiorgan ar...</td>\n",
              "      <td>mutate human genetic atlas multiorgan artifici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>MUTATE: a human genetic atlas of multiorgan ar...</td>\n",
              "      <td>mutate human genetic atlas multiorgan artifici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Disentangling Normal Aging From Severity of Di...</td>\n",
              "      <td>disentangling normal aging severity disease vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>CellTICS: an explainable neural network for ce...</td>\n",
              "      <td>celltics explainable neural network cell type ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>140</td>\n",
              "      <td>STAB2: an updated spatio-temporal cell atlas o...</td>\n",
              "      <td>stab updated spatio temporal cell atlas human ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>CirGRDB: a database for the genome-wide deciph...</td>\n",
              "      <td>cirgrdb database genome wide deciphering circa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>142</td>\n",
              "      <td>MethBank 4.0: an updated database of DNA methy...</td>\n",
              "      <td>methbank updated database dna methylation acro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>143</td>\n",
              "      <td>A metabolome atlas of the aging mouse brain. T...</td>\n",
              "      <td>metabolome atlas aging mouse brain mammalian b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>144</td>\n",
              "      <td>MassCube improves accuracy for metabolomics da...</td>\n",
              "      <td>masscube improves accuracy metabolomics data p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-159efc7a-05e6-449f-9fa8-25c16c7cd60e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-159efc7a-05e6-449f-9fa8-25c16c7cd60e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-159efc7a-05e6-449f-9fa8-25c16c7cd60e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-844e75b4-a47f-4a7e-8c5e-362936d235b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-844e75b4-a47f-4a7e-8c5e-362936d235b5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-844e75b4-a47f-4a7e-8c5e-362936d235b5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0b1ae329-eab8-4368-ae5f-45d410ef408d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0b1ae329-eab8-4368-ae5f-45d410ef408d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 145,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 0,\n        \"max\": 144,\n        \"num_unique_values\": 145,\n        \"samples\": [\n          69,\n          140,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 139,\n        \"samples\": [\n          \"CirGRDB: a database for the genome-wide deciphering circadian genes and regulators. Circadian rhythms govern various kinds of physiological and behavioral functions of the living organisms, and disruptions of the rhythms are highly detrimental to health. Although several databases have been built for circadian genes, a resource for comprehensive post-transcriptional regulatory information of circadian RNAs and expression patterns of disease-related circadian RNAs is still lacking. Here, we developed CirGRDB (http://cirgrdb.biols.ac.cn) by integrating more than 4936 genome-wide assays, with the aim of fulfilling the growing need to understand the rhythms of life. CirGRDB presents a friendly web interface that allows users to search and browse temporal expression patterns of interested genes in 37 human/mouse tissues or cell lines, and three clinical disorders including sleep disorder, aging and tumor. More importantly, eight kinds of potential transcriptional and post-transcriptional regulators involved in the rhythmic expression of the specific genes, including transcription factors, histone modifications, chromatin accessibility, enhancer RNAs, miRNAs, RNA-binding proteins, RNA editing and RNA methylation, can also be retrieved. Furthermore, a regulatory network could be generated based on the regulatory information. In summary, CirGRDB offers a useful repository for exploring disease-related circadian RNAs, and deciphering the transcriptional and post-transcriptional regulation of circadian rhythms.\",\n          \"BEATRICE: Bayesian Fine-mapping from Summary Data using Deep Variational Inference. MOTIVATION: We introduce a novel framework BEATRICE to identify putative causal variants from GWAS statistics. Identifying causal variants is challenging due to their sparsity and high correlation in the nearby regions. To account for these challenges, we rely on a hierarchical Bayesian model that imposes a binary concrete prior on the set of causal variants. We derive a variational algorithm for this fine-mapping problem by minimizing the KL divergence between an approximate density and the posterior probability distribution of the causal configurations. Correspondingly, we use a deep neural network as an inference machine to estimate the parameters of our proposal distribution. Our stochastic optimization procedure allows us to sample from the space of causal configurations, which we use to compute the posterior inclusion probabilities and determine credible sets for each causal variant. We conduct a detailed simulation study to quantify the performance of our framework against two state-of-the-art baseline methods across different numbers of causal variants and noise paradigms, as defined by the relative genetic contributions of causal and non-causal variants. RESULTS: We demonstrate that BEATRICE achieves uniformly better coverage with comparable power and set sizes, and that the performance gain increases with the number of causal variants. We also show the efficacy BEATRICE in finding causal variants from the GWAS study of Alzheimer's disease. In comparison to the baselines, only BEATRICE can successfully find the APOE epsilon2 allele, a commonly associated variant of Alzheimer's. AVAILABILITY: BEATRICE is available for download at https://github.com/sayangsep/Beatrice-Finemapping. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.\",\n          \"Multi-Modal Diagnosis of Alzheimer's Disease using Interpretable Graph Convolutional Networks. The interconnection between brain regions in neurological disease encodes vital information for the advancement of biomarkers and diagnostics. Although graph convolutional networks are widely applied for discovering brain connection patterns that point to disease conditions, the potential of connection patterns that arise from multiple imaging modalities has yet to be fully realized. In this paper, we propose a multi-modal sparse interpretable GCN framework (SGCN) for the detection of Alzheimer's disease (AD) and its prodromal stage, known as mild cognitive impairment (MCI). In our experimentation, SGCN learned the sparse regional importance probability to find signature regions of interest (ROIs), and the connective importance probability to reveal disease-specific brain network connections. We evaluated SGCN on the Alzheimer's Disease Neuroimaging Initiative database with multi-modal brain images and demonstrated that the ROI features learned by SGCN were effective for enhancing AD status identification. The identified abnormalities were significantly correlated with AD-related clinical symptoms. We further interpreted the identified brain dysfunctions at the level of large-scale neural systems and sex-related connectivity abnormalities in AD/MCI. The salient ROIs and the prominent brain connectivity abnormalities interpreted by SGCN are considerably important for developing novel biomarkers. These findings contribute to a better understanding of the network-based disorder via multi-modal diagnosis and offer the potential for precision diagnostics. The source code is available at https://github.com/Houliang-Zhou/SGCN.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 139,\n        \"samples\": [\n          \"cirgrdb database genome wide deciphering circadian gene regulator circadian rhythm govern various kind physiological behavioral function living organism disruption rhythm highly detrimental health although several database built circadian gene resource comprehensive post transcriptional regulatory information circadian rna expression pattern disease related circadian rna still lacking developed cirgrdb http cirgrdb biols ac cn integrating genome wide assay aim fulfilling growing need understand rhythm life cirgrdb present friendly web interface allows user search browse temporal expression pattern interested gene human mouse tissue cell line three clinical disorder including sleep disorder aging tumor importantly eight kind potential transcriptional post transcriptional regulator involved rhythmic expression specific gene including transcription factor histone modification chromatin accessibility enhancer rna mirnas rna binding protein rna editing rna methylation also retrieved furthermore regulatory network could generated based regulatory information summary cirgrdb offer useful repository exploring disease related circadian rna deciphering transcriptional post transcriptional regulation circadian rhythm\",\n          \"beatrice bayesian fine mapping summary data using deep variational inference motivation introduce novel framework beatrice identify putative causal variant gwas statistic identifying causal variant challenging due sparsity high correlation nearby region account challenge rely hierarchical bayesian model imposes binary concrete prior set causal variant derive variational algorithm fine mapping problem minimizing kl divergence approximate density posterior probability distribution causal configuration correspondingly use deep neural network inference machine estimate parameter proposal distribution stochastic optimization procedure allows u sample space causal configuration use compute posterior inclusion probability determine credible set causal variant conduct detailed simulation study quantify performance framework two state art baseline method across different number causal variant noise paradigm defined relative genetic contribution causal non causal variant result demonstrate beatrice achieves uniformly better coverage comparable power set size performance gain increase number causal variant also show efficacy beatrice finding causal variant gwas study alzheimer disease comparison baseline beatrice successfully find apoe epsilon allele commonly associated variant alzheimer availability beatrice available download http github com sayangsep beatrice finemapping supplementary information supplementary data available bioinformatics online\",\n          \"multi modal diagnosis alzheimer disease using interpretable graph convolutional network interconnection brain region neurological disease encodes vital information advancement biomarkers diagnostics although graph convolutional network widely applied discovering brain connection pattern point disease condition potential connection pattern arise multiple imaging modality yet fully realized paper propose multi modal sparse interpretable gcn framework sgcn detection alzheimer disease ad prodromal stage known mild cognitive impairment mci experimentation sgcn learned sparse regional importance probability find signature region interest roi connective importance probability reveal disease specific brain network connection evaluated sgcn alzheimer disease neuroimaging initiative database multi modal brain image demonstrated roi feature learned sgcn effective enhancing ad status identification identified abnormality significantly correlated ad related clinical symptom interpreted identified brain dysfunction level large scale neural system sex related connectivity abnormality ad mci salient roi prominent brain connectivity abnormality interpreted sgcn considerably important developing novel biomarkers finding contribute better understanding network based disorder via multi modal diagnosis offer potential precision diagnostics source code available http github com houliang zhou sgcn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr = df['processed_text'][:100]\n",
        "te = df['processed_text'][100:]"
      ],
      "metadata": {
        "id": "C2KzipMyWXiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the processed abstracts to a bag-of-words representation\n",
        "vectorizer = CountVectorizer()\n",
        "trX = vectorizer.fit_transform(tr)"
      ],
      "metadata": {
        "id": "w01gz7MSMcvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run LDA with topic number set to 6\n",
        "n_topics = 6\n",
        "lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
        "lda_model.fit(trX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "aiVBpXAIMnC0",
        "outputId": "349bba0e-da37-4853-a5a5-54c0258e8def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(n_components=6, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-21 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-21 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-21 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-21 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-21 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-21 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-21 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-21 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-21 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-21 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-21 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-21 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-21 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-21 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-21 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=6, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LatentDirichletAllocation(n_components=6, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Perplexity and Coherence Score\n",
        "def compute_coherence(lda_model, vectorizer, n_top_words=10):\n",
        "    topic_words = lda_model.components_\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    coherence = []\n",
        "    for topic in topic_words:\n",
        "        top_words_indices = topic.argsort()[-n_top_words:][::-1]\n",
        "        coherence_score = sum(topic[top_words_indices]) / n_top_words\n",
        "        coherence.append(coherence_score)\n",
        "    return sum(coherence) / len(coherence)"
      ],
      "metadata": {
        "id": "lqtihDtdMrtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Perplexity\n",
        "perplexity = lda_model.perplexity(trX)\n",
        "\n",
        "# Calculate Coherence score\n",
        "coherence_score_val = compute_coherence(lda_model, vectorizer)\n",
        "\n",
        "print(f\"Perplexity: {perplexity}\")   # lower the better\n",
        "print(f\"Coherence Score: {coherence_score_val}\")  # higher the better"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dia2vn9rMvJ8",
        "outputId": "6899d670-a13b-4da6-f2e0-c6ba083773cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 1496.4888419365739\n",
            "Coherence Score: 32.09124485951401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2# Function to summarize the topics\n",
        "def print_topic_keywords(model, vectorizer, n_top_words):\n",
        "    to_print = ''\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        to_print = to_print + f\"Topic {idx}:\\n\" + \" \".join([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-n_top_words:]]) + '\\n'\n",
        "\n",
        "    return to_print\n",
        "\n",
        "# Displaying the topics\n",
        "top_words = print_topic_keywords(lda_model, vectorizer, 10)\n",
        "print(top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao5xrptaMxz1",
        "outputId": "43ce477e-dedf-437c-e03e-cdf8f034cb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "alzheimer available network model based ad brain data method disease\n",
            "Topic 1:\n",
            "study clinical protein tremor data based region method model mri\n",
            "Topic 2:\n",
            "analysis network information genetic ad feature method disease gene data\n",
            "Topic 3:\n",
            "using gene ad study data deep image cell model disease\n",
            "Topic 4:\n",
            "method tool analysis available gwas data variant model network gene\n",
            "Topic 5:\n",
            "brain ferroptosis pyaging body event http ad aging disease editing\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "area = 'AI for health'"
      ],
      "metadata": {
        "id": "m1lsBmEyT-Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = f\"\"\"Given the fact that the following {n_topics} groups of words all originate from topic modeling of literature corpus in the area of {area}, what common denominator or topic do each of the following groups of words have? Please be as general and distinguishable among groups as possible, and save the result to a python list.\n",
        "{top_words}\"\"\"\n",
        "\n",
        "print(prompt1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMVlkANFM5u8",
        "outputId": "40b2793d-df8c-453e-aa31-1a0884650b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the fact that the following 6 groups of words all originate from topic modeling of literature corpus in the area of AI for health, what common denominator or topic do each of the following groups of words have? Please be as general and distinguishable among groups as possible, and save the result to a python list.\n",
            "Topic 0:\n",
            "alzheimer available network model based ad brain data method disease\n",
            "Topic 1:\n",
            "study clinical protein tremor data based region method model mri\n",
            "Topic 2:\n",
            "analysis network information genetic ad feature method disease gene data\n",
            "Topic 3:\n",
            "using gene ad study data deep image cell model disease\n",
            "Topic 4:\n",
            "method tool analysis available gwas data variant model network gene\n",
            "Topic 5:\n",
            "brain ferroptosis pyaging body event http ad aging disease editing\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt chatGPT5.1\n",
        "prompt1_topics = [\n",
        "    \"Alzheimer’s disease modeling using brain data and network-based methods\",\n",
        "    \"Clinical neuroimaging studies of neurological disorders and protein/tremor biomarkers\",\n",
        "    \"Genetic and network-based analyses of disease mechanisms\",\n",
        "    \"Deep learning on multimodal biological data for disease research\",\n",
        "    \"GWAS and variant-focused computational genetic analysis\",\n",
        "    \"Aging and neurodegeneration research involving cellular aging pathways\"\n",
        "]"
      ],
      "metadata": {
        "id": "rL7OX1n6TV-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = f\"\"\"You will receive a list of topics that belong to the same level of a topic hierarchy. Your task is to merge topics that are paraphrases or near duplicates of one another. Return 'None' if no modification is needed.\n",
        "\n",
        "Here are some examples:\n",
        "[Example 1]\n",
        "Topic List:\n",
        "<pairs of similar topics>\n",
        "\n",
        "Your response:\n",
        "<topics being merged into an existing topic>\n",
        "\n",
        "[Example 2]\n",
        "<pairs of similar topics>\n",
        "\n",
        "Your response:\n",
        "<topics being merged into a new topic>\n",
        "\n",
        "[Rules]\n",
        "- Each line represents a topic, with a level indicator and a topic label.\n",
        "- Perform the following operations as many times as needed:\n",
        "    - Merge relevant topics into a single topic.\n",
        "    - Do nothing and return 'None' if no modification is needed.\n",
        "- When merging, the output format should contain a level indicator, the updated label and description, followed by the original topics.\n",
        "\n",
        "\n",
        "[Topic List]\n",
        "{prompt1_topics}\n",
        "\n",
        "Output the modification or 'None' where appropriate. Do not output anything else.\n",
        "[Your response]\n",
        "\"\"\"\n",
        "\n",
        "print(prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIMnqKC5XON3",
        "outputId": "9e0123b1-a438-4bfd-83a9-f1b3ebc063ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You will receive a list of topics that belong to the same level of a topic hierarchy. Your task is to merge topics that are paraphrases or near duplicates of one another. Return 'None' if no modification is needed. \n",
            "\n",
            "Here are some examples: \n",
            "[Example 1]\n",
            "Topic List: \n",
            "<pairs of similar topics>\n",
            "\n",
            "Your response: \n",
            "<topics being merged into an existing topic>\n",
            "\n",
            "[Example 2]\n",
            "<pairs of similar topics>\n",
            "\n",
            "Your response: \n",
            "<topics being merged into a new topic>\n",
            "\n",
            "[Rules]\n",
            "- Each line represents a topic, with a level indicator and a topic label. \n",
            "- Perform the following operations as many times as needed: \n",
            "    - Merge relevant topics into a single topic.\n",
            "    - Do nothing and return 'None' if no modification is needed.\n",
            "- When merging, the output format should contain a level indicator, the updated label and description, followed by the original topics.\n",
            "\n",
            "\n",
            "[Topic List]\n",
            "['Alzheimer’s disease modeling using brain data and network-based methods', 'Clinical neuroimaging studies of neurological disorders and protein/tremor biomarkers', 'Genetic and network-based analyses of disease mechanisms', 'Deep learning on multimodal biological data for disease research', 'GWAS and variant-focused computational genetic analysis', 'Aging and neurodegeneration research involving cellular aging pathways']\n",
            "\n",
            "Output the modification or 'None' where appropriate. Do not output anything else. \n",
            "[Your response]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt2_results = None"
      ],
      "metadata": {
        "id": "AdxHC6wgZW86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# provide manual feedbacks to revise. Note UI cannot fit 100 documents together, so only put 10 as a demo; should use API calling for actual research.\n",
        "prompt3 = f\"\"\"You will receive {tr.shape[0]} documents and a set of top-level topics previously extracted from a topic hierarchy. Your task is, for each document, identify generalizable topics within the document that can act as top-level topics in the hierarchy. If any relevant topics are missing from the provided set, please add them. Otherwise, output the existing top-level topics as identified in the document.\n",
        "\n",
        "[Top-level topics]\n",
        "{prompt1_topics}\n",
        "\n",
        "[Examples]\n",
        "Example 1: Adding '[1] Data development for healthy aging or Alzheimer's disease'\n",
        "Document:\n",
        "Open datasets and code for multi-scale relations on structure, function and neuro-genetics in the human brain. The human brain is an extremely complex network of structural and functional connections that operate at multiple spatial and temporal scales. Investigating the relationship between these multi-scale connections is critical to advancing our comprehension of brain function and disorders. However, accurately predicting structural connectivity from its functional counterpart remains a challenging pursuit. One of the major impediments is the lack of public repositories that integrate structural and functional networks at diverse resolutions, in conjunction with modular transcriptomic profiles, which are essential for comprehensive biological interpretation. To mitigate this limitation, our contribution encompasses the provision of an open-access dataset consisting of derivative matrices of functional and structural connectivity across multiple scales, accompanied by code that facilitates the investigation of their interrelations. We also provide additional resources focused on neuro-genetic associations of module-level network metrics, which present promising opportunities to further advance research in the field of network neuroscience, particularly concerning brain disorders.\n",
        "\n",
        "Your response:\n",
        "[1] Data development for healthy aging or Alzheimer's disease: Mentions the provision of an open-access dataset for neuroscience and brain disorders.\n",
        "\n",
        "Example 2: Adding '[1] Hardware for healthy aging or Alzheimer's disease'\n",
        "Document:\n",
        "Helping Older Adults Hear in Noisy Social Situations Using Novel Hardware and AI. In the United States there are 37 million people with hearing loss but only 8 million wear hearing aids. Use of hearing aids by older adults slows the decline of thinking and memory abilities by 48%, making their low rate of adoption a big public health concern. The most common reason for not wearing hearing aids is difficulty participating in conversations in noisy social environments: family reunions, birthday parties, weddings, etc. Imagine a proud mom at her son\\u2019s wedding frustrated by loud noise instead of enjoying and reconnecting with her family & friends. Or an uncle struggling to catch up with their niece at the family thanksgiving party. AudioFocus is reimagining the hearing aid from the ground-up to solve this noise problem using AI. Their patented proximity-based speech enhancement algorithm enhances conversations in front of patients while suppressing noise from other conversations around them. To validate the benefits of their technology over existing AI hearing aids, they are running pilot studies with Dr. Reed from John Hopkins University, Dr. Fitzgerald from Stanford, and Dr. Hu from the University of the Pacific. AudioFocus\\u2019 team includes hearing aid science & engineering experts Dr. Shariq Mobin (PhD UC Berkeley, Google Brain) & Dr. Reza Kassayan (EarLens, Sonitus Medical). Dr. Shariq Mobin, PhD, Chief Scientific Officer of AudioFocus Professor Jiong \\u201cJoe\\u201d Hu, PhD, AuD, Vice Chair of Audiology at University of the Pacific\n",
        "\n",
        "Your response:\n",
        "[1] Hardware for healthy aging or Alzheimer's disease: Mentions using novel hardware to help older adults.\n",
        "\n",
        "[Instructions]\n",
        "For each document,\n",
        "Step 1: Determine topics mentioned in the document.\n",
        "- The topic labels must be a general research concept--from one of Data, Software method, Hardware--for AD or aging study. They must not be document-specific.\n",
        "- The topics must reflect a SINGLE topic instead of a combination of topics.\n",
        "- The new topics must have a level number, a short general label, and a topic description.\n",
        "- The topics must be broad enough to accommodate future subtopics.\n",
        "Step 2: Perform ONE of the following operations:\n",
        "1. If there are already duplicates or relevant topics in the hierarchy, output those topics and stop here.\n",
        "2. If the document contains no topic, return 'None'.\n",
        "3. Otherwise, add your topic as a top-level topic. Stop here and output the added topic(s). DO NOT add any additional levels.\n",
        "\n",
        "\n",
        "[Documents]\n",
        "{tr[:10].values}\n",
        "\n",
        "Please ONLY return the relevant or modified topics at the top level in the hierarchy. Your response should be in the python list format\n",
        "\n",
        "Your response:\n",
        "\"\"\"\n",
        "\n",
        "print(prompt3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kZDYtQ9Uw9j",
        "outputId": "d98971b3-52c0-41f5-ddbe-489ff5ef2490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You will receive 100 documents and a set of top-level topics previously extracted from a topic hierarchy. Your task is, for each document, identify generalizable topics within the document that can act as top-level topics in the hierarchy. If any relevant topics are missing from the provided set, please add them. Otherwise, output the existing top-level topics as identified in the document.\n",
            "\n",
            "[Top-level topics]\n",
            "['Alzheimer’s disease modeling using brain data and network-based methods', 'Clinical neuroimaging studies of neurological disorders and protein/tremor biomarkers', 'Genetic and network-based analyses of disease mechanisms', 'Deep learning on multimodal biological data for disease research', 'GWAS and variant-focused computational genetic analysis', 'Aging and neurodegeneration research involving cellular aging pathways']\n",
            "\n",
            "[Examples]\n",
            "Example 1: Adding '[1] Data development for healthy aging or Alzheimer's disease'\n",
            "Document:\n",
            "Open datasets and code for multi-scale relations on structure, function and neuro-genetics in the human brain. The human brain is an extremely complex network of structural and functional connections that operate at multiple spatial and temporal scales. Investigating the relationship between these multi-scale connections is critical to advancing our comprehension of brain function and disorders. However, accurately predicting structural connectivity from its functional counterpart remains a challenging pursuit. One of the major impediments is the lack of public repositories that integrate structural and functional networks at diverse resolutions, in conjunction with modular transcriptomic profiles, which are essential for comprehensive biological interpretation. To mitigate this limitation, our contribution encompasses the provision of an open-access dataset consisting of derivative matrices of functional and structural connectivity across multiple scales, accompanied by code that facilitates the investigation of their interrelations. We also provide additional resources focused on neuro-genetic associations of module-level network metrics, which present promising opportunities to further advance research in the field of network neuroscience, particularly concerning brain disorders.\n",
            "\n",
            "Your response:\n",
            "[1] Data development for healthy aging or Alzheimer's disease: Mentions the provision of an open-access dataset for neuroscience and brain disorders.\n",
            "\n",
            "Example 2: Adding '[1] Hardware for healthy aging or Alzheimer's disease'\n",
            "Document:\n",
            "Helping Older Adults Hear in Noisy Social Situations Using Novel Hardware and AI. In the United States there are 37 million people with hearing loss but only 8 million wear hearing aids. Use of hearing aids by older adults slows the decline of thinking and memory abilities by 48%, making their low rate of adoption a big public health concern. The most common reason for not wearing hearing aids is difficulty participating in conversations in noisy social environments: family reunions, birthday parties, weddings, etc. Imagine a proud mom at her son’s wedding frustrated by loud noise instead of enjoying and reconnecting with her family & friends. Or an uncle struggling to catch up with their niece at the family thanksgiving party. AudioFocus is reimagining the hearing aid from the ground-up to solve this noise problem using AI. Their patented proximity-based speech enhancement algorithm enhances conversations in front of patients while suppressing noise from other conversations around them. To validate the benefits of their technology over existing AI hearing aids, they are running pilot studies with Dr. Reed from John Hopkins University, Dr. Fitzgerald from Stanford, and Dr. Hu from the University of the Pacific. AudioFocus’ team includes hearing aid science & engineering experts Dr. Shariq Mobin (PhD UC Berkeley, Google Brain) & Dr. Reza Kassayan (EarLens, Sonitus Medical). Dr. Shariq Mobin, PhD, Chief Scientific Officer of AudioFocus Professor Jiong “Joe” Hu, PhD, AuD, Vice Chair of Audiology at University of the Pacific\n",
            "\n",
            "Your response:\n",
            "[1] Hardware for healthy aging or Alzheimer's disease: Mentions using novel hardware to help older adults.\n",
            "\n",
            "[Instructions]\n",
            "For each document,\n",
            "Step 1: Determine topics mentioned in the document.\n",
            "- The topic labels must be a general research concept--from one of Data, Software method, Hardware--for AD or aging study. They must not be document-specific.\n",
            "- The topics must reflect a SINGLE topic instead of a combination of topics.\n",
            "- The new topics must have a level number, a short general label, and a topic description.\n",
            "- The topics must be broad enough to accommodate future subtopics.\n",
            "Step 2: Perform ONE of the following operations:\n",
            "1. If there are already duplicates or relevant topics in the hierarchy, output those topics and stop here.\n",
            "2. If the document contains no topic, return 'None'.\n",
            "3. Otherwise, add your topic as a top-level topic. Stop here and output the added topic(s). DO NOT add any additional levels.\n",
            "\n",
            "\n",
            "[Documents]\n",
            "['convolutional neural network classification alzheimer disease overview reproducible evaluation numerous machine learning ml approach proposed automatic classification alzheimer disease ad brain imaging data particular paper proposed use convolutional neural network cnn ad classification anatomical mri however classification performance difficult compare across study due variation component participant selection image preprocessing validation procedure moreover study hardly reproducible framework publicly accessible implementation detail lacking lastly paper may report biased performance due inadequate unclear validation model selection procedure present work aim address limitation three main contribution first performed systematic literature review identified four main type approach slice level ii patch level iii roi based iv subject level cnn moreover found half surveyed paper may suffered data leakage thus reported biased performance second contribution extension open source framework classification ad using cnn weighted mri framework comprises previously developed tool automatically convert adni aibl oasis data bid standard modular set image preprocessing procedure classification architecture evaluation procedure dedicated deep learning finally used framework rigorously compare different cnn architecture data split training validation test set beginning training validation set used model selection avoid overfitting test set left untouched end peer review process overall different approach subject roi patch achieved similar performance slice approach lower note different cnn approach perform better svm voxel based feature different approach generalized well similar population datasets different inclusion criterion demographical characteristic code framework experiment publicly available general purpose tool integrated clinica software www clinica run paper specific code available http github com aramis lab ad dl'\n",
            " 'mutate human genetic atlas multiorgan artificial intelligence endophenotypes using genome wide association summary statistic artificial intelligence ai increasingly integrated imaging genetics provide intermediate phenotype e endophenotypes bridge genetics clinical manifestation human disease however genetic architecture ai endophenotypes remains largely unexplored context human multiorgan system disease using publicly available genome wide association study summary statistic uk biobank ukbb finngen psychiatric genomics consortium comprehensively depicted genetic architecture multiorgan ai endophenotypes maes comparatively assessed single nucleotide polymorphism based heritability polygenicity natural selection signature maes using method commonly used field genetic correlation mendelian randomization analysis reveal within organ relationship cross organ interconnection bi directional causal relationship established chronic human disease maes across multiple organ system including alzheimer disease brain diabetes metabolic system asthma pulmonary system hypertension cardiovascular system finally derived polygenic risk score maes individual used calculate maes returned ukbb finding underscore promise maes new instrument ameliorate overall human health result encapsulated multiorgan ai endophenotype genetic atlas publicly available http lab laboratory com mutate'\n",
            " 'mutate human genetic atlas multiorgan artificial intelligence endophenotypes using genome wide association summary statistic artificial intelligence ai increasingly integrated imaging genetics provide intermediate phenotype e endophenotypes bridge genetics clinical manifestation human disease however genetic architecture ai endophenotypes remains largely unexplored context human multiorgan system disease using publicly available genome wide association study summary statistic uk biobank ukbb finngen psychiatric genomics consortium comprehensively depicted genetic architecture multiorgan ai endophenotypes maes comparatively assessed single nucleotide polymorphism based heritability polygenicity natural selection signature maes using method commonly used field genetic correlation mendelian randomization analysis reveal within organ relationship cross organ interconnection bi directional causal relationship established chronic human disease maes across multiple organ system including alzheimer disease brain diabetes metabolic system asthma pulmonary system hypertension cardiovascular system finally derived polygenic risk score maes individual used calculate maes returned ukbb finding underscore promise maes new instrument ameliorate overall human health result encapsulated multiorgan ai endophenotype genetic atlas publicly available http lab laboratory com mutate'\n",
            " 'disentangling normal aging severity disease via weak supervision longitudinal mri continuous progression neurological disease often categorized condition according severity relate severity change brain morphometry growing interest replacing category continuous severity scale longitudinal mri mapped onto via deep learning algorithm however existing method based supervised learning require large number sample self supervised model fail clearly separate disease effect normal aging propose explicitly disentangle two factor via weak supervision word training based longitudinal mri labelled either normal diseased training data augmented sample disease category primary interest analysis encouraging trajectory control fully encoded direction associated brain aging furthermore orthogonal direction linked disease severity capture residual component normal aging diseased cohort hence proposed method quantifies disease severity progression speed individual without knowing condition apply proposed method data alzheimer disease neuroimaging initiative adni n show model properly disentangled normal aging severity cognitive impairment plotting resulting disentangled factor subject generating simulated mri given chronological age condition moreover representation obtains higher balanced accuracy used two downstream classification task compared pre training approach code weak supervised approach available http github com ouyangjiahong longitudinal direction disentangle'\n",
            " 'celltics explainable neural network cell type identification interpretation based single cell rna seq data identifying cell type crucial understanding functional unit organism machine learning shown promising performance identifying cell type many existing method lack biological significance due poor interpretability however utmost importance understand make cell share function form specific cell type motivating u propose biologically interpretable method celltics prioritizes marker gene cell type specific expression using hierarchy biological pathway neural network construction applying multi predictive layer strategy predict cell sub cell type celltics usually outperforms existing method prediction accuracy moreover celltics reveal pathway define cell type cell type specific physiological condition disease aging nonlinear nature neural network enables u identify many novel pathway interestingly pathway identified celltics exhibit differential expression variability rather differential expression across cell type indicating expression stochasticity within pathway could important feature characteristic cell type overall celltics provides biologically interpretable method identifying characterizing cell type shedding light underlying pathway define cellular heterogeneity role organismal function celltics available http github com qyyin celltics'\n",
            " 'ad syn net systematic identification alzheimer disease associated mutation co mutation vulnerability via deep learning alzheimer disease ad one challenging neurodegenerative disease complicated progressive mechanism multiple risk factor increasing research evidence demonstrates genetics may key factor responsible occurrence disease although previous report identified quite ad associated gene mostly limited owing patient sample size selection bias lack comprehensive research aimed identify ad associated risk mutation systematically address challenge hereby construct large scale ad mutation co mutation framework ad syn net propose deep learning model named deep smci deep cmci configured fully connected layer capable predicting cognitive impairment subject effectively based genetic mutation co mutation profile next apply customized framework data set evaluate importance score mutation identified mutation effector co mutation combination vulnerability contributing cognitive impairment furthermore evaluate influence mutation pair network architecture dissect genetic organization ad identify novel co mutation could responsible dementia laying solid foundation proposing future targeted therapy ad precision medicine deep learning model code available open access http github com pan bio ad mutation effector'\n",
            " 'adeditome provides genomic landscape rna editing alzheimer disease rna editing contributing nearly editing event human reported involve pathogenesis alzheimer disease ad due role brain development immune regulation deficient editing glua q r related cell death memory loss currently urgent need systematic annotation rna editing event ad built adeditome annotation database rna editing ad available http ccsm uth edu adeditome aiming provide resource reference functional annotation rna editing ad identify therapeutically targetable gene individual detected editing site sample across nine brain region rosmap mayornaseq msbb editing event performed multiple functional annotation including identification specific disease stage associated editing event influence editing event gene expression protein recoding alternative splicing mirna regulation gene especially ad related gene order explore pathology ad combing analysis result found editing event may promote inhibit ad progression respectively also found brain region specific editing event potentially dual role ad across different brain region adeditome unique resource ad drug research community identify therapeutically targetable editing event significance adeditome first comprehensive resource functional genomics individual rna editing event ad useful many researcher field ad pathology precision medicine therapeutic research'\n",
            " 'self supervised learning neighborhood embedding longitudinal mri recent year several deep learning model recommend first represent magnetic resonance imaging mri latent feature performing downstream task interest classification regression performance downstream task generally improves latent representation explicitly associated factor interest example derived representation capturing brain aging applying self supervised learning longitudinal mri used resulting encoding automatically identify disease accelerating aging brain propose refinement representation replacing linear modeling brain aging one consistent local neighborhood latent space called longitudinal neighborhood embedding lne derive encoding neighborhood age consistent e brain mri different subject similar brain age close proximity progression consistent e latent space defined smooth trajectory field trajectory capture change brain age pair mri extracted longitudinal sequence make problem computationally tractable propose strategy mini batch sampling resulting local neighborhood accurately approximate one would defined based whole cohort evaluate lne three different downstream task predict chronological age w mri healthy subject participating study sri international distinguish normal control nc alzheimer disease ad stable mild cognitive impairment smci progressive mild cognitive impairment pmci based w mri participant alzheimer disease neuroimaging initiative adni distinguish low moderate heavy alcohol drinker based fractional anisotropy derived diffusion tensor mri adolescent recruited national consortium alcohol neurodevelopment adolescence ncanda across three data set visualization smooth trajectory vector field superior accuracy downstream task demonstrate strength proposed method existing self supervised method extracting information related brain aging could help study impact substance use neurodegenerative disorder code available http github com ouyangjiahong longitudinal neighbourhood embedding'\n",
            " 'aiteq machine learning framework alzheimer prediction using distinctive five gene signature neurodegenerative disease alzheimer disease pose significant global health challenge complex etiology elusive biomarkers study developed alzheimer identification tool aiteq using ribonucleic acid sequencing rna seq machine learning ml model based optimized ensemble algorithm identification alzheimer rna seq data analysis rna seq data several study identified differentially expressed gene followed ml protocol involving feature selection model training performance evaluation hyperparameter tuning feature selection process undertaken study employing combination four different methodology culminated identification compact yet impactful set five gene twelve diverse ml model trained tested using five gene cnksr epha clspn olfml tarbp performance metric including precision recall f score accuracy matthew correlation coefficient receiver operating characteristic area curve assessed finally selected model overall ensemble model consisting logistic regression naive bayes classifier support vector machine optimized hyperparameters identified best used develop aiteq aiteq available http github com ishtiaque ahammad aiteq'\n",
            " 'alzriskmr database online database impact exposure factor alzheimer disease view great difficulty pathogenesis analysis alzheimer disease ad presently profiling modifiable risk factor crucial early detection intervention ad however causal association among yet identified effective integration application data also remain considerable challenge due lack efficient collection analysis procedure address issue performed comprehensive analysis two sample mendelian randomization smr established alzriskmr database http github com sdbmc riskfactors ad four smr analysis method including inverse variance weighted ivw mr egger weighted median weighted mode used complementary calculation test reliability result database currently comprises set data genome wide association study gwas mr base nhgri ebi gwas catalog database alzriskmr database estimate causal association modifiable risk factor ad also offer useful timely resource early intervention ad development incidence']\n",
            "\n",
            "Please ONLY return the relevant or modified topics at the top level in the hierarchy. Your response should be in the python list format\n",
            "\n",
            "Your response:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually evaluation the results: if not correct, add human demonstration of corrected examples in prompt3 above to iteratively refine\n",
        "prompt3_results = [\n",
        "\"Deep learning on multimodal biological data for disease research\",\n",
        "\"GWAS and variant-focused computational genetic analysis\",\n",
        "\"GWAS and variant-focused computational genetic analysis\",\n",
        "\"Aging and neurodegeneration research involving cellular aging pathways\",\n",
        "\"Deep learning on multimodal biological data for disease research\",\n",
        "\"Genetic and network-based analyses of disease mechanisms\",\n",
        "\"Genetic and network-based analyses of disease mechanisms\",\n",
        "\"Aging and neurodegeneration research involving cellular aging pathways\",\n",
        "\"Deep learning on multimodal biological data for disease research\",\n",
        "\"GWAS and variant-focused computational genetic analysis\"\n",
        "]"
      ],
      "metadata": {
        "id": "_ZC-YdmvdLOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can try with different LLMs and topic modeling methods. When use API calling, the above iterative procedures can mitigate the scalability issue.\n",
        "\n",
        "The LDA codes above were actually generated by gpt-4o-mini within a multiagent framework via Autogen. It showcases the entire topic modeling pipeline can be built with agentic framework with little to none human intervention. Below is an example prompt you can try (using gensim LDA instead of sklearn as above)."
      ],
      "metadata": {
        "id": "tHCM_cz5ipDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_persona=\"\"\"Forget about all the previous conversation. You are the expert in AI and NLP. Suggests a plan for topic modeling using Latent Dirichlet Allocation (LDA).\n",
        "    The plan includes:\n",
        "    1. Preprocessing text (DataPreprocessor).\n",
        "    2. Running LDA for multiple topic numbers (LDATopicModeling).\n",
        "    3. Evaluating coherence and perplexity scores.\n",
        "    4. Choosing the best topic number.\n",
        "    5. Summarizing topics with topN words (TopicSummarizer).\n",
        "    6. Generating prompts for LLMs to interpret the topics (TopicDescriptor).\n",
        "    Write python codes for these steps.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "-WO4WIyHjJhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlieZ3w2mfey",
        "outputId": "694dc417-df8d-4444-da3c-1ef59935af84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "End-to-end LDA topic modeling pipeline:\n",
        "\n",
        "1. DataPreprocessor       – text cleaning + tokenization (+ optional bigrams)\n",
        "2. LDATopicModeling       – train LDA for multiple topic numbers\n",
        "3. evaluate_models        – compute coherence & perplexity\n",
        "4. choose_best_topic_num  – pick best #topics\n",
        "5. TopicSummarizer        – top-N words per topic\n",
        "6. TopicDescriptor        – generate LLM prompts for topic interpretation\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import string\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "\n",
        "# Make sure NLTK stopwords are available once in your environment:\n",
        "# >>> import nltk\n",
        "# >>> nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# 1. -----------------------------------------------------------\n",
        "#    DataPreprocessor\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \"\"\"\n",
        "    Basic text preprocessing for LDA:\n",
        "      - lowercasing\n",
        "      - removing punctuation & digits\n",
        "      - tokenization\n",
        "      - stopword removal\n",
        "      - optional bigram detection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        language: str = \"english\",\n",
        "        min_token_len: int = 2,\n",
        "        use_bigrams: bool = True,\n",
        "        bigram_min_count: int = 10,\n",
        "        bigram_threshold: float = 10.0,\n",
        "    ):\n",
        "        self.language = language\n",
        "        self.stop_words = set(stopwords.words(language))\n",
        "        self.min_token_len = min_token_len\n",
        "\n",
        "        self.use_bigrams = use_bigrams\n",
        "        self.bigram_min_count = bigram_min_count\n",
        "        self.bigram_threshold = bigram_threshold\n",
        "        self.bigram_model = None  # set in fit()\n",
        "\n",
        "    @staticmethod\n",
        "    def _basic_clean(text: str) -> str:\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"\\s+\", \" \", text)  # normalize spaces\n",
        "        # keep letters and spaces; strip digits/punct\n",
        "        text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "\n",
        "    def _tokenize(self, text: str) -> List[str]:\n",
        "        tokens = text.split()\n",
        "        tokens = [\n",
        "            t\n",
        "            for t in tokens\n",
        "            if t not in self.stop_words and len(t) >= self.min_token_len\n",
        "        ]\n",
        "        return tokens\n",
        "\n",
        "    def fit(self, documents: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Learn bigram model (if enabled). Must be called before transform().\n",
        "        \"\"\"\n",
        "        cleaned_docs = [self._basic_clean(doc) for doc in documents]\n",
        "        tokenized_docs = [self._tokenize(doc) for doc in cleaned_docs]\n",
        "\n",
        "        if self.use_bigrams:\n",
        "            phrases = Phrases(\n",
        "                tokenized_docs,\n",
        "                min_count=self.bigram_min_count,\n",
        "                threshold=self.bigram_threshold,\n",
        "            )\n",
        "            self.bigram_model = Phraser(phrases)\n",
        "\n",
        "    def transform(self, documents: List[str]) -> List[List[str]]:\n",
        "        \"\"\"\n",
        "        Apply preprocessing (and bigrams, if fitted) to raw docs.\n",
        "        \"\"\"\n",
        "        cleaned_docs = [self._basic_clean(doc) for doc in documents]\n",
        "        tokenized_docs = [self._tokenize(doc) for doc in cleaned_docs]\n",
        "\n",
        "        if self.use_bigrams and self.bigram_model is not None:\n",
        "            tokenized_docs = [self.bigram_model[doc] for doc in tokenized_docs]\n",
        "\n",
        "        return tokenized_docs\n",
        "\n",
        "    def fit_transform(self, documents: List[str]) -> List[List[str]]:\n",
        "        self.fit(documents)\n",
        "        return self.transform(documents)\n",
        "\n",
        "\n",
        "# 2. -----------------------------------------------------------\n",
        "#    LDATopicModeling\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "class LDATopicModeling:\n",
        "    \"\"\"\n",
        "    Handles:\n",
        "      - building gensim dictionary & corpus\n",
        "      - training LDA for multiple topic numbers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenized_docs: List[List[str]],\n",
        "        no_below: int = 5,\n",
        "        no_above: float = 0.5,\n",
        "        keep_n: int = 50000,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        tokenized_docs: list of lists of tokens (output of DataPreprocessor)\n",
        "        \"\"\"\n",
        "        self.tokenized_docs = tokenized_docs\n",
        "        self.dictionary = corpora.Dictionary(tokenized_docs)\n",
        "        self.dictionary.filter_extremes(no_below=no_below, no_above=no_above, keep_n=keep_n)\n",
        "        self.corpus = [self.dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
        "        self.models: Dict[int, LdaModel] = {}\n",
        "\n",
        "    def train_models(\n",
        "        self,\n",
        "        topic_nums: List[int],\n",
        "        passes: int = 10,\n",
        "        iterations: int = 200,\n",
        "        random_state: int = 42,\n",
        "        alpha: str = \"auto\",\n",
        "        eta: str = \"auto\",\n",
        "    ) -> Dict[int, LdaModel]:\n",
        "        \"\"\"\n",
        "        Train an LDA model for each k in topic_nums.\n",
        "        \"\"\"\n",
        "        for k in topic_nums:\n",
        "            lda = LdaModel(\n",
        "                corpus=self.corpus,\n",
        "                id2word=self.dictionary,\n",
        "                num_topics=k,\n",
        "                passes=passes,\n",
        "                iterations=iterations,\n",
        "                random_state=random_state,\n",
        "                alpha=alpha,\n",
        "                eta=eta,\n",
        "                eval_every=None,  # we'll evaluate separately\n",
        "            )\n",
        "            self.models[k] = lda\n",
        "        return self.models\n",
        "\n",
        "\n",
        "# 3. -----------------------------------------------------------\n",
        "#    Evaluation: coherence & perplexity\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "def evaluate_models(\n",
        "    lda_pipeline: LDATopicModeling,\n",
        "    coherence_metric: str = \"c_v\",\n",
        ") -> Dict[int, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Compute coherence and perplexity for each trained model.\n",
        "\n",
        "    Returns:\n",
        "      {\n",
        "        k: {'coherence': float, 'perplexity': float},\n",
        "        ...\n",
        "      }\n",
        "    \"\"\"\n",
        "    scores: Dict[int, Dict[str, float]] = {}\n",
        "\n",
        "    for k, model in lda_pipeline.models.items():\n",
        "        coherence_model = CoherenceModel(\n",
        "            model=model,\n",
        "            texts=lda_pipeline.tokenized_docs,\n",
        "            dictionary=lda_pipeline.dictionary,\n",
        "            coherence=coherence_metric,\n",
        "        )\n",
        "        coherence = coherence_model.get_coherence()\n",
        "\n",
        "        # Gensim's log_perplexity is negative; higher (less negative) is better\n",
        "        log_perplexity = model.log_perplexity(lda_pipeline.corpus)\n",
        "        # Convert to a \"perplexity-like\" positive value if desired:\n",
        "        # perplexity = math.exp(-log_perplexity)\n",
        "\n",
        "        scores[k] = {\n",
        "            \"coherence\": coherence,\n",
        "            \"log_perplexity\": log_perplexity,\n",
        "        }\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "# 4. -----------------------------------------------------------\n",
        "#    Choose best topic number\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "def choose_best_topic_num(\n",
        "    scores: Dict[int, Dict[str, float]],\n",
        "    weight_coherence: float = 1.0,\n",
        "    weight_perplexity: float = 0.0,\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Select best k given evaluation scores.\n",
        "\n",
        "    Default: only coherence (max coherence).\n",
        "    You can incorporate perplexity by setting weight_perplexity > 0.\n",
        "\n",
        "    Note: log_perplexity is typically negative; higher is better.\n",
        "    \"\"\"\n",
        "\n",
        "    # Normalize metrics for simple weighted scoring\n",
        "    coherences = [v[\"coherence\"] for v in scores.values()]\n",
        "    perps = [v[\"log_perplexity\"] for v in scores.values()]\n",
        "\n",
        "    min_coh, max_coh = min(coherences), max(coherences)\n",
        "    min_perp, max_perp = min(perps), max(perps)\n",
        "\n",
        "    def normalize(x, xmin, xmax):\n",
        "        if xmax == xmin:\n",
        "            return 0.5  # avoid div by zero; neutral\n",
        "        return (x - xmin) / (xmax - xmin)\n",
        "\n",
        "    best_k = None\n",
        "    best_score = float(\"-inf\")\n",
        "\n",
        "    for k, vals in scores.items():\n",
        "        coh_norm = normalize(vals[\"coherence\"], min_coh, max_coh)\n",
        "        perp_norm = normalize(vals[\"log_perplexity\"], min_perp, max_perp)\n",
        "\n",
        "        combined_score = weight_coherence * coh_norm + weight_perplexity * perp_norm\n",
        "\n",
        "        if combined_score > best_score:\n",
        "            best_score = combined_score\n",
        "            best_k = k\n",
        "\n",
        "    return best_k\n",
        "\n",
        "\n",
        "# 5. -----------------------------------------------------------\n",
        "#    TopicSummarizer\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "class TopicSummarizer:\n",
        "    \"\"\"\n",
        "    Extract top-N words per topic from an LDA model.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def summarize_topics(\n",
        "        lda_model: LdaModel,\n",
        "        topn: int = 10\n",
        "    ) -> Dict[int, List[str]]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          {topic_id: [word1, word2, ...], ...}\n",
        "        \"\"\"\n",
        "        topic_terms: Dict[int, List[str]] = {}\n",
        "\n",
        "        for topic_id in range(lda_model.num_topics):\n",
        "            terms = lda_model.show_topic(topic_id, topn=topn)\n",
        "            topic_terms[topic_id] = [word for word, _ in terms]\n",
        "\n",
        "        return topic_terms\n",
        "\n",
        "\n",
        "# 6. -----------------------------------------------------------\n",
        "#    TopicDescriptor (LLM prompts)\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "class TopicDescriptor:\n",
        "    \"\"\"\n",
        "    Generate prompts for LLMs to interpret topics.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def build_prompts_for_llm(\n",
        "        topic_words: Dict[int, List[str]],\n",
        "        domain_hint: str = \"AI and health\",\n",
        "        style: str = \"concise and high-level\"\n",
        "    ) -> Dict[int, str]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          {topic_id: prompt_string, ...}\n",
        "        \"\"\"\n",
        "        prompts: Dict[int, str] = {}\n",
        "\n",
        "        for topic_id, words in topic_words.items():\n",
        "            word_list_str = \", \".join(words)\n",
        "            prompt = (\n",
        "                f\"You are an expert in {domain_hint}. \"\n",
        "                f\"Given the following topic keywords:\\n\"\n",
        "                f\"{word_list_str}\\n\\n\"\n",
        "                f\"1. Provide a {style} description of the main theme of this topic.\\n\"\n",
        "                f\"2. Suggest a short, general topic label (no more than 10 words).\\n\"\n",
        "                f\"3. Optionally, list 2–3 possible subtopics.\\n\"\n",
        "            )\n",
        "            prompts[topic_id] = prompt\n",
        "\n",
        "        return prompts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jsbQIClrkW1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Example usage (wire everything together)\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# Example corpus (replace with your own documents)\n",
        "raw_documents = df['text'][:100].to_list()\n",
        "# raw_documents = [\n",
        "#     \"Alzheimer's disease is a progressive neurodegenerative disorder affecting memory.\",\n",
        "#     \"We used MRI scans and deep learning to classify Alzheimer's disease.\",\n",
        "#     \"Genome-wide association studies reveal genetic variants associated with dementia.\",\n",
        "#     \"Aging is associated with changes in brain structure and cognitive decline.\",\n",
        "#     \"Deep learning methods can model complex relationships in multimodal health data.\",\n",
        "#     \"RNA-seq data can identify biomarkers for neurodegenerative diseases.\",\n",
        "# ]\n",
        "\n",
        "# 1. Preprocess\n",
        "preprocessor = DataPreprocessor(use_bigrams=True)\n",
        "tokenized_docs = preprocessor.fit_transform(raw_documents)\n",
        "\n",
        "# 2. Train LDA for multiple topic numbers\n",
        "lda_pipeline = LDATopicModeling(tokenized_docs)\n",
        "topic_nums_to_try = [5,6,7]\n",
        "lda_models = lda_pipeline.train_models(topic_nums_to_try)\n",
        "\n",
        "# 3. Evaluate models\n",
        "scores = evaluate_models(lda_pipeline, coherence_metric=\"c_v\")\n",
        "print(\"Scores (k -> metrics):\")\n",
        "for k, m in scores.items():\n",
        "    print(f\"k={k}: coherence={m['coherence']:.4f}, log_perplexity={m['log_perplexity']:.4f}\")\n",
        "\n",
        "# 4. Choose best topic number (here, coherence-only)\n",
        "best_k = choose_best_topic_num(scores, weight_coherence=1.0, weight_perplexity=0.0)\n",
        "best_model = lda_models[best_k]\n",
        "print(f\"\\nBest number of topics: {best_k}\")\n",
        "\n",
        "# 5. Summarize topics with top-N words\n",
        "summarizer = TopicSummarizer()\n",
        "topic_words = summarizer.summarize_topics(best_model, topn=10)\n",
        "print(\"\\nTop words per topic:\")\n",
        "for tid, words in topic_words.items():\n",
        "    print(f\"Topic {tid}: {', '.join(words)}\")\n",
        "\n",
        "# 6. Generate LLM prompts to interpret topics\n",
        "descriptor = TopicDescriptor()\n",
        "prompts = descriptor.build_prompts_for_llm(\n",
        "    topic_words,\n",
        "    domain_hint=\"AI and neurodegenerative disease research\",\n",
        "    style=\"succinct, expert-level\"\n",
        ")\n",
        "\n",
        "print(\"\\nExample LLM prompts:\")\n",
        "for tid, prompt in prompts.items():\n",
        "    print(f\"\\n--- Prompt for Topic {tid} ---\\n{prompt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7euxqIkpmpIq",
        "outputId": "b81ddeec-a05c-46c4-9a91-567b3398260e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores (k -> metrics):\n",
            "k=5: coherence=0.2624, log_perplexity=-6.2448\n",
            "k=6: coherence=0.2714, log_perplexity=-6.2598\n",
            "k=7: coherence=0.2998, log_perplexity=-6.2594\n",
            "\n",
            "Best number of topics: 7\n",
            "\n",
            "Top words per topic:\n",
            "Topic 0: mri, deep, regions, across, human, pipeline, predicting, proteins, clinical, framework\n",
            "Topic 1: brain, disease, method, prediction, datasets, analysis, diseases, mri, ad, proposed\n",
            "Topic 2: genes, tool, pipeline, time, gene, analysis, genetic, available, key, variants\n",
            "Topic 3: genes, ad, methods, performance, dataset, gwas, genetic, method, human, different\n",
            "Topic 4: drug, aging, gene, online, analysis, available, supplementary_information, rna, software, seq\n",
            "Topic 5: ad, network, information, framework, aging, genes, multi_modal, features, diagnosis, functional\n",
            "Topic 6: longitudinal, brain, disease, imaging, analysis, genetic, snps, methods, method, variants\n",
            "\n",
            "Example LLM prompts:\n",
            "\n",
            "--- Prompt for Topic 0 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "mri, deep, regions, across, human, pipeline, predicting, proteins, clinical, framework\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 1 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "brain, disease, method, prediction, datasets, analysis, diseases, mri, ad, proposed\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 2 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "genes, tool, pipeline, time, gene, analysis, genetic, available, key, variants\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 3 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "genes, ad, methods, performance, dataset, gwas, genetic, method, human, different\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 4 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "drug, aging, gene, online, analysis, available, supplementary_information, rna, software, seq\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 5 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "ad, network, information, framework, aging, genes, multi_modal, features, diagnosis, functional\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n",
            "\n",
            "--- Prompt for Topic 6 ---\n",
            "You are an expert in AI and neurodegenerative disease research. Given the following topic keywords:\n",
            "longitudinal, brain, disease, imaging, analysis, genetic, snps, methods, method, variants\n",
            "\n",
            "1. Provide a succinct, expert-level description of the main theme of this topic.\n",
            "2. Suggest a short, general topic label (no more than 10 words).\n",
            "3. Optionally, list 2–3 possible subtopics.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Y7j2iEunVAo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
